{
    "name": "BERT-Pretrain-common-MAA-NGPUs",
    "n_gpu": 1,

    "dataset": {
        "type": "MAADataset",
        "args":{
            "seq_dir": "../ProcessedData/OAS_covid_light/light_data_demo.csv",
            "token_length_list": "2,3",
            "vocab_dir": "../ProcessedData/vocab/heavy-2-3.csv",
            "seed": 0,
            "seq_name": "light",
            "tokenizer_name": "common",
            "max_len": 128,
            "test_split": 0.001
        }
    },

    "model": {
        "bert": "roformer",
        "args":{
            "hidden_size": 768,
            "num_hidden_layers": 12,
            "num_attention_heads": 12,
            "intermediate_size": 1536,
            "hidden_act": "gelu",
            "hidden_dropout_prob": 0.1,
            "attention_probs_dropout_prob": 0.1,
            "max_position_embeddings": 512,
            "type_vocab_size": 2,
            "initializer_range": 0.02,
            "position_embedding_type": "absolute"
        }
    },

    "metrics":{
        "blosum_dir": "../RawData/blosum62.json",
        "blosum": true
    },

    "trainer": {
        "epochs": 20,
        "batch_size": 128,
        "save_dir": "../Result_covid_light/",
        "lr": 5e-5,
        "warmup": 0.1,
        "eval_accumulation_steps": 32,
        "logging_steps": 500
    }

}